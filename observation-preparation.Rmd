---
title: "observation-preparation"
author: "jafshin & StevePem"
date: "14/05/2021"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(fs)
library(sf)
library(lubridate)
library(readxl)
# library(rosm)
library(ggspatial)
library(lwgeom)
library(stringr)
library(igraph)
library(nngeo)  # for st_azimuth

source('./functions/addNetworkDetails.R')

```

```{r road network data}

networkFile <- "./data/networks/MATSimMelbNetwork.sqlite"

# read in links and nodes
networkLinks <- st_read(networkFile, layer = "links", quiet=T) %>%
  mutate(link_id = row_number()) 
  
networkNodes <- st_read(networkFile, layer = "nodes", quiet=T) 

```

## Car traffic data

### Car traffic data cleaning 

Reading input 

```{r}
###############################################################################
# Day of Week where 1=Monday, 2=Tuesday,3=Wednesday,                          #
# 4=Thursday,5=Friday,6=Saturday and 7=Sunday                                 #
###############################################################################
# A=Actual count, Ehis=Estimate based on historic data,                       #
# Egmr=Estimate based on global substitution, Erte=Estimate based on route    #
###############################################################################

col_spec <- cols(
  .default = col_double(),
  HMGNS_LNK_DESC = col_character(),
  FLOW = col_character(),
  COUNT_TYPE = col_character(),
  PERIOD_TYPE = col_character()
)

# carData <- read_csv("~/ownCloud/io.github.jafshin/calibration-validation/data/observations/car/TYPICAL_HOURLY_VOLUME_DATA.csv", col_types = col_spec)
carData <- read_csv("./data/observations/car/TYPICAL_HOURLY_VOLUME_DATA.csv", 
                    col_types = col_spec)

carDataFiltered <- carData %>% 
  filter(PERIOD_TYPE=="SCHOOL TERM/NORMAL") %>% 
  filter(DOW==3) %>% 
  # Filter to those with high enough number traffic
  mutate(HMGNS_FLOW_ID=as.character(HMGNS_FLOW_ID)) %>% 
  mutate(HMGNS_LNK_ID=as.character(HMGNS_LNK_ID)) %>% 
  dplyr::select(-DOW) %>% 
  mutate(totalVol=rowSums(across(where(is.numeric)))) 

```

Reading Greater Melbourne Boundaries for mapping:

```{r}
# GMelbBoundary <- read_sf("~/ownCloud/io.github.jafshin/calibration-validation/data/boundaries/ABS_Boundaries/1270055001_sa1_2016_aust_shape/SA1_2016_AUST.shp") %>% 
GMelbBoundary <- read_sf("./data/boundaries/1270055001_sa1_2016_aust_shape/SA1_2016_AUST.shp") %>% 
  st_transform(28355) %>% 
  filter(GCC_NAME16=="Greater Melbourne") %>% 
  summarise(geometry=st_union(geometry)) 
```

Adding geometry to the roads

```{r}
# TIS_ROUTE_FLOW=	Traffic Information Route Flow (1=Generally out of Melb, Generally 0= into Melb)
# HMGNS_FLOW_ID	Text	10	Homogeneous flow id eg 1234. An internal reference for Homogenous Flow. Homogeneous flow - The traffic volume information associated with the traffic flow along a link that is representative of all travel along the whole link
# ROAD_NBR	Number	8	ROAD_NUMBER

# htvnData <- st_read("~/ownCloud/io.github.jafshin/calibration-validation/data/observations/car/homogenous_traffic_flow-shp/3ad2d9d5-dd49-40bf-86c4-ccf114d2e4582020328-1-cs85vw.3kgy7.shp") %>% 
htvnData <- st_read("./data/observations/car/homogenous_traffic_flow-shp/3ad2d9d5-dd49-40bf-86c4-ccf114d2e4582020328-1-cs85vw.3kgy7.shp") %>% 
  st_transform(28355) %>% 
  mutate(HMGNS_FLOW_ID=as.character(HMGNS_FLOW))
carDataJoined <- carDataFiltered %>%
  left_join(htvnData, by="HMGNS_FLOW_ID") %>% 
  st_as_sf()
st_write(carDataJoined, "carDataJoined.sqlite", delete_dsn = T)
```

Crop to greater Melbourne

```{r}
# gMelbBoundary <- st_read("~/ownCloud/Data/ABS_Boundaries/GreaterMelbourneArea/GMEL_SA4_2016_Polygons.sqlite")  %>% 
gMelbBoundary <- st_read("./data/boundaries/GreaterMelbourneArea/GMEL_SA4_2016_Polygons.sqlite")  %>% 
  st_transform(28355) %>%
  summarise()  # to dissolve SA4s (without this, roads get split at SA4 boundaries)
  
carDataCroped <- carDataJoined %>% 
  st_intersection(gMelbBoundary)

st_write(carDataCroped, "carDataCropedSmall.sqlite", delete_dsn = T)
```

### AM Peak data

```{r}

amCarData <- carDataCroped %>% 
  filter(TIS_ROUTE1==0)

```

finding high volume AM roads

```{r}

amHighVolRoads <- amCarData %>% 
  st_drop_geometry() %>% 
  group_by(ROAD_NBR) %>% 
  summarise(roadVol=mean(totalVol)) %>% 
  slice_max(order_by = roadVol, prop=0.1)

amHighVolCarData <- amCarData %>% 
  filter(ROAD_NBR %in% amHighVolRoads$ROAD_NBR) %>% 
  group_by(ROAD_NBR) %>% 
  slice_max(order_by = totalVol, n=1)

st_write(amHighVolCarData, "amHighVolCarData.sqlite", delete_dsn = T)
```

Plot of AM Peak Count locations

```{r}
amHighVolCarData %>% 
  ggplot() +
  annotation_map_tile(type="osmgrayscale",zoom=9, alpha=0.6) +
  geom_sf(aes(fill=totalVol)) +
  scale_fill_viridis_c(trans = "sqrt", alpha = .8) 

```

### PM Peak data

```{r}

pmCarData <- carDataCroped %>% 
  filter(TIS_ROUTE1==1)

```

finding high volume PM roads

```{r}

pmHighVolRoads <- pmCarData %>% 
  st_drop_geometry() %>% 
  group_by(ROAD_NBR) %>% 
  summarise(roadVol=mean(totalVol)) %>% 
  slice_max(order_by = roadVol, prop=0.1)
pmHighVolCarData <- pmCarData %>% 
  filter(ROAD_NBR %in% pmHighVolRoads$ROAD_NBR) %>% 
  group_by(ROAD_NBR) %>% 
  slice_max(order_by = totalVol, n=1)
st_write(pmHighVolCarData, "pmHighVolCarData.sqlite", delete_dsn = T)
```

Plot of AM Peak Count locations

```{r}
pmHighVolCarData %>% 
  ggplot() +
  annotation_map_tile(type="osmgrayscale",zoom=9, alpha=0.6) +
  geom_sf(aes(fill=totalVol)) +
  scale_fill_viridis_c(trans = "sqrt", alpha = .8) 
```

### Adding links from MATSim Network

Add to AM peak data

```{r}

amHighVolCarData <- addCarLinks(carData = "./amHighVolCarData.sqlite", 
                                layer = "amhighvolcardata",
                                links= networkLinks,
                                nodes= networkNodes)
st_write(amHighVolCarData, "amHighVolCarData.sqlite", delete_dsn = T)
glimpse(amHighVolCarData)

```

Add to PM peak data

Notes:
- Road 23, METROPOLITAN RING ROAD btwn METROPOLITAN RING ROAD Offramp & WESTERN RING ROAD, may wrongly select an offramp instead of a section of the Ring Road

```{r}
pmHighVolCarData <- addCarLinks(carData = "./pmHighVolCarData.sqlite", 
                                layer = "pmhighvolcardata",
                                links= networkLinks,
                                nodes= networkNodes)
st_write(pmHighVolCarData, "pmHighVolCarData.sqlite", delete_dsn = T)
glimpse(pmHighVolCarData)

```

## Bicycle traffic simulation

Reading the input files

```{r}
# paths <- dir_ls("~/ownCloud/io.github.jafshin/calibration-validation/data/observations/bicycle/2018-03/",glob = "*.zip" )
paths <- dir_ls("./data/observations/bicycle/2018-03/",glob = "*.zip" )
# Extracting all the bike count data
walk(paths, ~unzip(.x, exdir = "data/cyclingVolFiles"))
# reading the data it
cyclingVol_paths <- dir_ls("./data/cyclingVolFiles/")
col_spec <- cols(
  DATA_TYPE = col_character(),
  TIS_DATA_REQUEST = col_double(),
  SITE_XN_ROUTE = col_double(),
  LOC_LEG = col_double(),
  DATE = col_character(),
  TIME = col_time(format = ""),
  CLASS = col_double(),
  LANE = col_double(),
  SPEED = col_double(),
  WHEELBASE = col_double(),
  HEADWAY = col_double(),
  GAP = col_double(),
  AXLE = col_double(),
  AXLE_GROUPING = col_double(),
  RHO = col_double(),
  VEHICLE = col_character(),
  DIRECTION = col_character()
)
cyclingVol <- map_dfr(cyclingVol_paths, ~ read_csv(.x, col_types = col_spec))
```

A quick look at what we've got

```{r}
glimpse(cyclingVol)
```

Filtering to mid-week day data

```{r}
cyclingVolFiltered <- cyclingVol %>% 
  filter(!DATE%in%c("12/03/2018", "30/03/2018", "31/03/2018")) %>% # Removing public holidays
  mutate(DATE=dmy(DATE)) %>% 
  mutate(DOW = wday(DATE, label=TRUE)) %>% 
  filter(DOW%in%c("Tue", "Wed", "Thu")) # Selecting mid-week days
```

Counting cycling trips based on counter location, direction, date and hour of the day

```{r}
cyclingVolCounted <- cyclingVolFiltered %>% 
  mutate(hour=hour(TIME)) %>% 
  group_by(SITE_XN_ROUTE, LOC_LEG, DIRECTION, DATE, hour) %>% 
  summarise(count=n()) %>% 
  ungroup()
glimpse(cyclingVolCounted)
```

Aggregating count data by averaging over all days

```{r}
cyclingVolAverage <- cyclingVolCounted %>% 
  group_by(SITE_XN_ROUTE, LOC_LEG, DIRECTION, hour) %>% 
  summarise(avgCount=round(mean(count))) %>% 
  ungroup() %>% 
  mutate(siteNumber=as.character(SITE_XN_ROUTE)) %>% 
  mutate(directionID=as.character(LOC_LEG)) %>% 
  dplyr::select(siteNumber, directionID, dir=DIRECTION, hour, count=avgCount) 
glimpse(cyclingVolAverage)
```

### Having a look at the final data 

```{r}
cyclingVolAverage %>% count(siteNumber, directionID, dir) %>% 
  ggplot(aes(x=dir, y=n))+
  geom_col(aes(fill=dir))
```

Plotting one of the count locations

```{r}
cyclingVolAverage %>% filter(siteNumber==6411) %>% 
  ggplot(aes(x=hour, y=count)) +
  geom_point(aes(color=dir)) +
  geom_line(aes(color=dir))
```

Plotting aggregated values 

```{r}
cyclingVolAverage %>% 
  group_by(hour, siteNumber) %>% 
  summarise(routeVol=sum(count)) %>%
  summarise(totalVol=mean(routeVol)) %>% 
  ggplot(aes(x=hour, y=totalVol)) +
  geom_point() +
  geom_line()
```

### Adding coordinates to the count points

Reading the location points

```{r}
# cycleCountersMeta <- read_xlsx("~/ownCloud/io.github.jafshin/calibration-validation/data/observations/bicycle/VicRoads_Bike_Site_Number_Listing.xlsx",
cycleCountersMeta <- read_xlsx("./data/observations/bicycle/VicRoads_Bike_Site_Number_Listing.xlsx",
          skip=2, col_names=c("id", "site", "gps", "desc", "comment")) 
cycleCountersMeta %>% glimpse()
```

Adding the location points and MATSim network links to the count data

Notes:
- VicRoads site no 7, (BIKE LANE) FLEMINGTON RD NB 10M SE OF DRYBURGH ST, may select the link in Flemington Road immediately north-east of Dryburgh St, rather than immediately south-east
- VicRoads site no 10, (BIKE LANE) ROYAL PDE NB 10M N OF GATEHOUSE ST, may select the link in Royal Pd immediately south of Gatehouse St, rather than immediately north


```{r}
cyclingVolCoordinated <- addBikeLinks(cyclingVolAverage = cyclingVolAverage,
                                      cycleCountersMeta = cycleCountersMeta,
                                      networkLinks,
                                      networkNodes)
st_write(cyclingVolCoordinated, "cyclingVolCoordinated.sqlite", delete_layer=T)
cyclingVolCoordinated %>% glimpse()
```

Mapping selected cycling count locations

```{r}
cyclingVolCoordinated %>% 
  group_by(siteNumber,directionID) %>% 
  summarise(totalVol=sum(count)) %>%  
  ggplot() +
  annotation_map_tile(type="osmgrayscale",zoom=10, alpha=0.8) +
  geom_sf(aes(color=totalVol))  
```

## Walking Data

Reading the walk count data
Source data: 
https://data.melbourne.vic.gov.au/Transport/Pedestrian-Counting-System-Monthly-counts-per-hour/b2ak-trbp

```{r}
col_spec <- cols(
  ID = col_double(),
  Date_Time = col_character(),
  Year = col_double(),
  Month = col_character(),
  Mdate = col_double(),
  Day = col_character(),
  Time = col_double(),
  Sensor_ID = col_double(),
  Sensor_Name = col_character(),
  Hourly_Counts = col_double()
)
# walkData <- read_csv("~/ownCloud/io.github.jafshin/calibration-validation/data/observations/walk/Pedestrian_Counting_System_-_Monthly__counts_per_hour_.csv", col_types = col_spec) 
walkData <- read_csv("./data/observations/walk/Pedestrian_Counting_System_-_Monthly__counts_per_hour_.csv", col_types = col_spec) 
walkData %>% glimpse()
```

```{r}
walkDataFiltered <- walkData %>% 
  filter(Year==2018,Month=="March") %>% 
  filter(Day%in%c("Tuesday", "Wednesday", "Thursday"))
walkDataFiltered %>% count(Year,Month,Day)
```

```{r}
walkDataFiltered %>% glimpse()
```

### Adding location to the count data

Source for sensor locations:
https://data.melbourne.vic.gov.au/Transport/Pedestrian-Counting-System-Sensor-Locations/h57g-5234

```{r}
col_spec <- cols(
  sensor_id = col_double(),
  sensor_description = col_character(),
  sensor_name = col_character(),
  installation_date = col_date(format = ""),
  status = col_character(),
  note = col_character(),
  direction_1 = col_character(),
  direction_2 = col_character(),
  latitude = col_double(),
  longitude = col_double(),
  location = col_character()
)
# walkSensorLocs <- read_csv("~/ownCloud/io.github.jafshin/calibration-validation/data/observations/walk/Pedestrian_Counting_System_-_Sensor_Locations.csv", col_types = col_spec)
walkSensorLocs <- read_csv("./data/observations/walk/Pedestrian_Counting_System_-_Sensor_Locations.csv", col_types = col_spec)
walkSensorLocs %>% glimpse()
```

```{r}
walkDataJoined <- walkDataFiltered %>% 
  left_join(walkSensorLocs, by=c("Sensor_ID"="sensor_id")) 
walkDataJoined %>% glimpse()
```


```{r}
walkDataCoordinated <- walkDataJoined %>% 
  st_as_sf(coords = c("longitude", "latitude"), crs = 4326) %>% 
  st_transform(28355) %>% 
  dplyr::select(ID,Sensor_ID, Sensor_Name, Hourly_Counts, direction_1, 
                direction_2, Time, geometry)
st_write(walkDataCoordinated, "walkDataCoordinated.sqlite", delete_layer=T)
walkDataCoordinated %>% glimpse()
```

Mapping walking count point locations

```{r}
walkDataCoordinated %>% 
  group_by(Sensor_ID) %>% 
  summarise(totalVol=sum(Hourly_Counts)) %>% 
  ggplot() +
  annotation_map_tile(type="osmgrayscale",zoom=12, alpha=0.8) +
  geom_sf(aes(color=totalVol))  
```

### Adding links from MATSim Network

Each Sensor has two directions (eg direction_1: North; direction_2: South).  This step adds fields link_row_1, from_id_1 and to_id_2 for the MATSim Network links and nodes for direction_1; and link_row_2, from_id_2 and to_id_2 for direction_2.

Many Sensors are on one side of a road only, eg Sensor 36 (Queen St near Collins St, west side). In that case, usually the links for the Sensor are:
- the same, being a two-directional link that represents the relevant road/path, or
- different, representing two one-directional links that each represent the relevant road/path.
In these caes, as the Sensor is on one side of the road only, its observations should cover about 50% of the total number of pedestrians using the link or links in both directions (that is, the pedestrians walking on both sides of the road).

In other cases, the Sensor represents the whole of a path in both directions, eg Sensor 25 (shared use path near Melbourne Convention & Exhibition Centre).  In that case, usually the link for the sensor is a two-directional link that represents the path.  Its observations should cover the total number of pedestrians using the link in both directions.

However, there are many cases where a road is represented by two two-directional links; or by three or four links.  In these cases, one or two of these links will be selected for the Sensor, but the Sensor's observations will include pedestrians using both the selected links, and other unselected links that also represent the same road.  Examples include the following Sensors:
- 1 & 2 (Bourke St Mall - 3 links)
- 4, 15, 54 & 66 (locations in Swanston St - two 2-way links: footway and roadway)
- 17 & 18 (Collins St near Exhibition St - two 2-way links: footway and roadway)
- 21 (Russel St near Bourke St - 4 links)
- 30 & 56 (locations in Lonsdale St - 3 links)
- 44 (Swanston St near Elgin St - 3 links)
- 48 (Victoria St near Elizabeth St - two 2-way links: footway and roadway)
- 49 (Therry St - 2-way walkway and 1-way roadway)
- 64 (Royal Pde near Grattan St - 3 links)
- 75 (Spring St near Flinders St - 3 links)

Sensor 5 (Princes Bridge) selects the link in Swanston St just north of Princes Bridge, rather than Princes Bridge itself.  This is not necessarily a bad outcome, because the link which represents Princes Bridge is selected by Sensor 29 (St Kilda Rd - Alexandra Gardens).

Sensors 19 & 20 (Little Bourke Street) return NA results in eastbound direction.  This is because the street is one way, and there is no adjacent walking link in the correct direction.

Sensor 57 (Bourke St Bridge) selects a link which crosses Wurundjeri Way (as the Bourke St Bridge does); but the full bridge across the rail station is not included in the MATSim Network, so cannot be selected.

Sensors 77 and 78 (Harbour Esplanade pedestrian path and bike path) both select the same link.  This is because that link represents both of those paths in the MATSim network.


```{r}
walkDataCoordinated <- addWalkLinks(walkData = "./walkDataCoordinated.sqlite", 
                                    layer = "walkdatacoordinated",
                                    walkSensorLocs = walkSensorLocs,
                                    networkLinks,
                                    networkNodes)

st_write(walkDataCoordinated, "walkDataCoordinated.sqlite", delete_dsn = T)

walkDataCoordinated %>% glimpse()

```

## Public transport

### Station patronage

Reading stations' patronage survey data

```{r}

# stationData <- readxl::read_excel("~/ownCloud/io.github.jafshin/calibration-validation/data/observations/pt/2016 Station Access Mode.xlsx",sheet = "Sheet2", skip = 3)  
stationData <- readxl::read_excel("./data/observations/pt/2016 Station Access Mode.xlsx",sheet = "Sheet2", skip = 3)  

  
stationDataFiltered <- stationData %>%   
  dplyr::select(-`Station Group`) %>% 
  filter(!is.na(Station)) %>% 
  mutate(stationID=stringr::str_extract(Station,pattern = "[0-9]+"))  %>% 
  mutate(stationName=stringr::str_extract(Station,pattern = "[A-z](.*)"))  
```

Reading stop locations from GTFS data

```{r}
col_spec <- cols(
  stop_id = col_double(),
  stop_name = col_character(),
  stop_lat = col_double(),
  stop_lon = col_double()
)

# stationLocations <- read_csv("~/ownCloud/io.github.jafshin/calibration-validation/data/observations/pt/stops.txt", col_types = col_spec) %>% 
stationLocations <- read_csv("./data/observations/pt/stops.txt", col_types = col_spec) %>% 
  mutate(stationID=as.character(stop_id)) %>% 
  # filter to rows containing 'Railway Station' and not '/' (used for bus or tram stops at stations) 
  filter(grepl("Railway Station", stop_name) & !grepl("/", stop_name)) %>%
  # replace the pattern 'space + Railway + any number of other characters' with nothing
  mutate(stationName = gsub(" Railway.*","", stop_name)) %>%
  # fix some name mismatches between patronage and GTFS names
  mutate(stationName = if_else(stationName=="McKinnon", "Mckinnon",
                               if_else(stationName=="Jolimont-MCG", "Jolimont",
                                       if_else(stationName=="Showgrounds", "Showgrounds Station",
                                               stationName)))) %>%
  dplyr::select(stationName, stop_lat, stop_lon)

```

Joining stop locations to the patronage data

```{r}
stationDataCoordinated <- stationDataFiltered %>% 
  left_join(stationLocations, by="stationName") %>%
  # remove duplicates (eg where Vline contains metro and Vline with same name)
  distinct(stationName, .keep_all=T)  

write_csv(stationDataCoordinated, "stationDataCoordinated.csv")
stationDataCoordinated %>% glimpse()

```

Plotting the Station data

```{r}
stationDataWithGeom <- stationDataCoordinated %>% 
  filter(!is.na(stop_lat)) %>% 
  st_as_sf(coords = c("stop_lon", "stop_lat"), remove=F, crs = 4326) %>% 
  st_transform(28355) %>% 
  dplyr::select(stationName, stationID, Total=`Total Result`, geometry)


```

Map of the train stops included for the calibration: 

```{r}
stationDataWithGeom %>% 
  st_intersection(GMelbBoundary) %>% 
  ggplot() +
  annotation_map_tile(type="osmgrayscale",zoom=9) +
  geom_sf(aes(color=Total, size= Total)) +
  scale_fill_viridis_c(trans = "sqrt", alpha = .4) 

```

```{r}
st_write(stationDataWithGeom, "stationDataWithGeom.sqlite", delete_dsn = T)
```

### Adding nodes from MATSim Network

Add station nodes

```{r}
stationDataWithGeom <- addStationNodes(patronageData = "./stationDataWithGeom.sqlite", 
                                       layer = "stationdatawithgeom",
                                       networkLinks,
                                       networkNodes)
st_write(stationDataWithGeom, "stationDataWithGeom.sqlite", delete_dsn = T)


# Check that result is a connected network (except for Showgrounds and Flemington Racecourse)
# Note that there are also  other links for express services
# Note link gap between Highett and Cheltenham, because Southland station missing from patronage data
rail.lines <- networkLinks %>%
  filter(from_id %in% stationDataWithGeom$node_id & to_id %in% stationDataWithGeom$node_id)

ggplot() + 
  geom_sf(data = stationDataWithGeom, color = 'red') +
  geom_sf(data = rail.lines, color = 'blue')

```

Further check that results form a connected graph of 216 stations

```{r}
# make graph to check that all stops are in fact connected
rail.graph <- graph_from_data_frame(rail.lines, directed = F) %>%
  suppressWarnings()

# count vertices in largest subgraph
components <- clusters(rail.graph)
biggest_cluster_id <- which.max(components$csize)
vertices <- V(rail.graph)[components$membership == biggest_cluster_id]
no.vertices <- length(vertices)
no.vertices  # should be 216 (218 stations in patronage data, excl. Showgrounds and Flemington Racecourse)

```


#### Other potential sources for pt data: 
 - Train: https://philipmallis.com/blog/2019/02/14/station-patronage-in-victoria-2013-2018/
- Bus: https://discover.data.vic.gov.au/dataset/ptv-metro-tram-stops